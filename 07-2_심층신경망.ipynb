{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "(X_train, y_train),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 픽셀값 0~ 255를 0~1 fh, 28*28 2차원 배열을 784크기에 1차원으로\n",
    "# 검증셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_train_scaled = X_train_scaled.reshape(-1,28*28)\n",
    "\n",
    "X_train_scaled, val_scaled, y_train, y_val = \\\n",
    "    train_test_split(X_train_scaled, y_train, test_size= 0.25) \n",
    "\n",
    "# 층을 2 개 만들어 sequential()에 추가해본다.\n",
    "# hidden_layer에는 sigmoid_function을 활성함수로 한다.\n",
    "# input_shape=(28*28,) 는 keras.Input(shape=(28*28,))을 \n",
    "# 명시적으로 해주는것과 동일하다\n",
    "dense1 =keras.layers.Dense(100, activation='sigmoid',input_shape=(28*28,))\n",
    "dense2 = keras.layers.Dense(10,activation='softmax')\n",
    "\n",
    "model = keras.Sequential([\n",
    "    dense1,\n",
    "    dense2\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#기본 미니배치는 32이다. fit() 에서 batch_size로 변경가능\n",
    "# param값 = 모든 조합에대한 가중치 + 각 절편\n",
    "# Non-trainable params SGD로 훈련되지않은 파라미터를 가진층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션_MNIST_모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential 클래스에 층을 추가하는 다른 방법 1\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,),\n",
    "                       name='hidden'),\n",
    "    keras.layers.Dense(10,activation='softmax', name='output')\n",
    "],name='패션_MNIST_모델')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 150)               117750    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138410 (540.66 KB)\n",
      "Trainable params: 138410 (540.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 층을 추가하는 다른방법 2 add()\n",
    "# 장점: 조건에따라 층을 추가하는 구성을 할수있다.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(150, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(100,activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(50,activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 9s 5ms/step - loss: 0.8303 - acc: 0.7073\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4542 - acc: 0.8374\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3996 - acc: 0.8555\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3690 - acc: 0.8664\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3477 - acc: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x225e2b0ccd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='acc')\n",
    "model.fit(X_train_scaled,y_train,epochs=5)\n",
    "#층이 없던것보다 성능이 향상됐다.\n",
    "# 어떻게 구성해야 최대의 정확도를 얻을수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84060 (328.36 KB)\n",
      "Trainable params: 84060 (328.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 직접 이미지를 1차원으로 reshape하지않고 Flatten 층을 이용할수있다.\n",
    "# Flatten은 학습층이아니다. 따라서 모델 깊이가 3이다.\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 7s 4ms/step - loss: 0.5292 - acc: 0.8107\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3897 - acc: 0.8598\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3560 - acc: 0.8732\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3359 - acc: 0.8797\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3254 - acc: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x225e2af7910>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train_scaled = x_train / 255.0\n",
    "\n",
    "x_train_scaled, val_scaled, y_train, y_val = \\\n",
    "    train_test_split(x_train_scaled, y_train, test_size= 0.25) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics='acc')\n",
    "model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3738 - acc: 0.8694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3737983703613281, 0.8694000244140625]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증셋 정확도 확인\n",
    "model.evaluate(val_scaled,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 6s 3ms/step - loss: 0.5335 - acc: 0.8136\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3984 - acc: 0.8582\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3568 - acc: 0.8716\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3326 - acc: 0.8796\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3129 - acc: 0.8865\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3452 - acc: 0.8749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34522852301597595, 0.8749333620071411]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터: 은닉층 개수, 뉴런수, 활성화함수종류, 층의 종류, 배치사이즈,에포크수 등\n",
    "# 옵티마이저: 학습률조절하는 방법, 이것도 하이퍼파라미터이다.\n",
    "# sgd = keras.optimizers.SGD(learning_rate=0.1) # 초기화해서 컴파일에 넣어주는것과 동일하다.\n",
    "# model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics='acc')\n",
    "\n",
    "model =keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "# adam : RMSprop와 모멘텀 최적화의 장점을 합친것  \n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy'\\\n",
    "    ,metrics='acc')\n",
    "model.fit(x_train_scaled,y_train,epochs=5)\n",
    "\n",
    "model.evaluate(val_scaled, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
